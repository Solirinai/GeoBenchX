{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tasks for benchmarking set\n",
    "\n",
    "This notebook is for generating the tasks for benchmarking. Generation requires the seed tasks prepared by researchers. \n",
    "\n",
    "After generating the draft tasks with LLM, be sure to read them carefully and make mindful selection for the benchmarking set, so the set meets your research criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from geobenchx.constants import MODEL_CLAUDE, DATA_FOLDER\n",
    "from geobenchx.dataclasses import Task, TaskSet\n",
    "from geobenchx.tools import (\n",
    "    get_unique_values_tool, \n",
    "    load_data_tool, \n",
    "    load_geodata_tool, \n",
    "    make_choropleth_map_tool, \n",
    "    make_bivariate_map_tool,\n",
    "    merge_dataframes_tool, \n",
    "    filter_categorical_tool, \n",
    "    filter_numerical_tool,\n",
    "    select_features_by_spatial_relationship_tool,\n",
    "    filter_points_by_raster_values_tool,\n",
    "    create_buffer_tool,\n",
    "    get_raster_path_tool,\n",
    "    get_raster_description_tool,\n",
    "    get_values_from_raster_with_geometries_tool,\n",
    "    analyze_raster_overlap_tool,\n",
    "    calculate_line_lengths_tool,\n",
    "    calculate_columns_tool,\n",
    "    scale_column_by_value_tool,\n",
    "    make_heatmap_tool,\n",
    "    visualize_geographies_tool,\n",
    "    get_centroids_tool,\n",
    "    generate_contours_display_tool,\n",
    "    calculate_column_statistics_tool,\n",
    "    DATA_CATALOG, GEO_CATALOG, COLORMAPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports related to Anthropic APIs\n",
    "\n",
    "# Loading API key\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook constants\n",
    "TEMPERATURE = 0\n",
    "GENERATE_FEASIBLE = 80\n",
    "GENERATE_CONFUSING = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the generation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making list of tools for the TOOLS_PROMPT\n",
    "\n",
    "tools_prompt_text =[]\n",
    "\n",
    "tools_list = [\n",
    "    get_unique_values_tool, \n",
    "    load_data_tool, \n",
    "    load_geodata_tool, \n",
    "    make_choropleth_map_tool, \n",
    "    make_bivariate_map_tool,\n",
    "    merge_dataframes_tool, \n",
    "    filter_categorical_tool, \n",
    "    filter_numerical_tool,\n",
    "    select_features_by_spatial_relationship_tool,\n",
    "    filter_points_by_raster_values_tool,\n",
    "    create_buffer_tool,\n",
    "    get_raster_path_tool,\n",
    "    get_raster_description_tool,\n",
    "    get_values_from_raster_with_geometries_tool,\n",
    "    analyze_raster_overlap_tool,\n",
    "    calculate_line_lengths_tool,\n",
    "    calculate_columns_tool,\n",
    "    scale_column_by_value_tool,\n",
    "    make_heatmap_tool,\n",
    "    visualize_geographies_tool,\n",
    "    get_centroids_tool,\n",
    "    generate_contours_display_tool,\n",
    "    calculate_column_statistics_tool\n",
    "]\n",
    "for item in tools_list:\n",
    "    tool_name = item.name\n",
    "    tool_desc = item.description\n",
    "    # tool_code = inspect.getsource(item.func)\n",
    "    tools_prompt_text.append(f\"{tool_name}\\n{tool_desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS_PROMPT = f\"\"\"\n",
    "COLORMAPS = {COLORMAPS}\n",
    "\n",
    "{tools_prompt_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PROMPT = f\"\"\"\n",
    "DATA_CATALOG = {DATA_CATALOG} \n",
    "\n",
    "GEO_CATALOG = {GEO_CATALOG}\n",
    "\n",
    "In the file with geometries (countries), the countries assigned to various regions. Available classifications:\n",
    "REGION_WB:'East Asia & Pacific',  'Latin America & Caribbean',  'Europe & Central Asia',  'South Asia',  'Middle East & North Africa',  'Sub-Saharan Africa',  'North America',  'Antarctica'.\n",
    "SUBREGION: 'South-Eastern Asia',\n",
    " 'South America',\n",
    " 'Western Asia',\n",
    " 'Southern Asia',\n",
    " 'Eastern Asia',\n",
    " 'Eastern Africa',\n",
    " 'Western Europe',\n",
    " 'Northern Africa',\n",
    " 'Central America',\n",
    " 'Middle Africa',\n",
    " 'Eastern Europe',\n",
    " 'Southern Africa',\n",
    " 'Caribbean',\n",
    " 'Central Asia',\n",
    " 'Northern Europe',\n",
    " 'Southern Europe',\n",
    " 'Western Africa',\n",
    " 'Northern America',\n",
    " 'Melanesia',\n",
    " 'Australia and New Zealand',\n",
    " 'Polynesia',\n",
    " 'Seven seas (open ocean)',\n",
    " 'Micronesia'.\n",
    "REGION_UN: 'Asia', 'Americas', 'Africa', 'Europe', 'Oceania', 'Seven seas (open ocean)'.\n",
    "CONTINENT:'Asia',  'South America',  'Africa',  'Europe',  'North America',  'Oceania',  'Seven seas (open ocean)'\n",
    "INCOME_GRP:'4. Lower middle income',  '3. Upper middle income',  '2. High income: nonOECD',  '1. High income: OECD',  '5. Low income'\n",
    "\n",
    "Timeseries in the statistical data go back to 1960 and have columns for every year since then. Not all of them have full set of data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING_PROMPT = f\"\"\"\n",
    "You are testing a Large Language Model (LLM) for its ability to solve tasks requiring some geospatial operations. The LLM will use function/tool calling to solve tasks.\n",
    "You provide the LLM with a list of tools.\n",
    "<TOOLS> {TOOLS_PROMPT}</TOOLS>\n",
    "You provide the LLM with datasets and geometries:\n",
    "<DATA> {DATA_PROMPT}</DATA>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SETTING_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examples of tasks for the group 'Process - Merge - Visualize'\n",
    "\n",
    "# feasible_tasks_examples = f\"\"\"\n",
    "# 1) Make a map of level of usage of water resources in countries of Africa.\n",
    "# Solution: \n",
    "# 1. load_data(dataset='Annual freshwater withdrawals, total (% of internal resources)', output_dataframe_name='water_usage') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries') \n",
    "# 3. filter_categorical(dataframe_name='countries', output_dataframe_name='african_countries', filters=\"CONTINENT\": \"Africa\") \n",
    "# 4. merge_dataframes(statkey='Country Name', geokey='NAME_EN', dataframe_name='water_usage', geodataframe_name='african_countries', output_dataframe_name='african_water_usage') \n",
    "# 5. make_map(colormap='Water', dataframe_name='african_water_usage', legendtext='Annual freshwater withdrawals, total (% of internal resources)', mappingkey='2021') \n",
    " \n",
    "# 2) Make a series of maps with share of forest covered areas in countries of South Asia in 2005, 2015 and the last available year.\n",
    "# Solution:\n",
    "# 1. load_data(dataset='Forest area (% of land area)', output_dataframe_name='forest_data') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries') \n",
    "# 3. filter_categorical(dataframe_name='countries', filters='REGION_WB': 'South Asia', output_dataframe_name='south_asia') \n",
    "# 4. merge_dataframes(dataframe_name='forest_data', geodataframe_name='south_asia', statkey='Country Name', geokey='NAME_EN', output_dataframe_name='south_asia_forest') \n",
    "# 5. make_map(dataframe_name='south_asia_forest', mappingkey='2005', legendtext='Forest area (% of land area) in 2005', colormap='Forest') \n",
    "# 6. make_map(dataframe_name='south_asia_forest', mappingkey='2015', legendtext='Forest area (% of land area) in 2015', colormap='Forest') \n",
    "# 7. make_map(dataframe_name='south_asia_forest', mappingkey='2021', legendtext='Forest area (% of land area) in 2021', colormap='Forest')\n",
    " \n",
    "# 3) Make a series of separate maps of electric consumption per capita per country for subregions of Europe.\n",
    "# Solution:\n",
    "# 1. load_data(dataset='Electric power consumption (kWh per capita)', output_dataframe_name='power_data') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries_geo') \n",
    "# 3. merge_dataframes(dataframe_name='power_data', geodataframe_name='countries_geo', statkey='Country Name', geokey='NAME_EN', output_dataframe_name='merged_power') \n",
    "# 4. filter_categorical(dataframe_name='merged_power', filters='CONTINENT': 'Europe', output_dataframe_name='europe_power') \n",
    "# 5. get_unique_values(dataframe_name='europe_power', column='SUBREGION') \n",
    "# 6. filter_categorical(dataframe_name='europe_power', filters='SUBREGION': 'Western Europe', output_dataframe_name='western_europe') \n",
    "# 7. make_map(dataframe_name='western_europe', mappingkey='2014', legendtext='Electric power consumption (kWh per capita) - Western Europe', colormap='Economics') \n",
    "# 8. filter_categorical(dataframe_name='europe_power', filters='SUBREGION': 'Eastern Europe', output_dataframe_name='eastern_europe') \n",
    "# 9. make_map(dataframe_name='eastern_europe', mappingkey='2014', legendtext='Electric power consumption (kWh per capita) - Eastern Europe', colormap='Economics') \n",
    "# 10. filter_categorical(dataframe_name='europe_power', filters='SUBREGION': 'Northern Europe', output_dataframe_name='northern_europe') \n",
    "# 11. make_map(dataframe_name='northern_europe', mappingkey='2014', legendtext='Electric power consumption (kWh per capita) - Northern Europe', colormap='Economics') \n",
    "# 12. filter_categorical(dataframe_name='europe_power', filters='SUBREGION': 'Southern Europe', output_dataframe_name='southern_europe') \n",
    "# 13. make_map(dataframe_name='southern_europe', mappingkey='2014', legendtext='Electric power consumption (kWh per capita) - Southern Europe', colormap='Economics')\n",
    " \n",
    "# 4) Visualize annual freshwater withdrawals in Asia.\n",
    "# Solution:\n",
    "# 1. load_data(dataset='Annual freshwater withdrawals, total (billion cubic meters)', output_dataframe_name='water_data') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries_geo') \n",
    "# 3. merge_dataframes(dataframe_name='water_data', geodataframe_name='countries_geo', statkey='Country Name', geokey='NAME_EN', output_dataframe_name='merged_water') \n",
    "# 4. filter_categorical(dataframe_name='merged_water', filters='CONTINENT': 'Asia', output_dataframe_name='asia_water') \n",
    "# 5. make_map(dataframe_name='asia_water', mappingkey='2021', legendtext='Annual freshwater withdrawals (billion cubic meters)', colormap='Water')\n",
    " \n",
    "# 5) Visualize how contribution of agriculture to GDP varies in countries of Americas.\n",
    "# Solution:\n",
    "# 1. load_data(dataset='Agriculture, value added (% of GDP)', output_dataframe_name='agri_gdp') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries') \n",
    "# 3. merge_dataframes(dataframe_name='agri_gdp', geodataframe_name='countries', statkey='Country Name', geokey='NAME_EN', output_dataframe_name='merged_data') \n",
    "# 4. filter_categorical(dataframe_name='merged_data', filters=\"CONTINENT\": \"North America\", \"South America\", output_dataframe_name='americas_data') \n",
    "# 5. make_map(dataframe_name='americas_data', mappingkey='2021', legendtext='Agriculture, value added (% of GDP)', colormap='Agriculture')\n",
    "\n",
    "# 6) Map greenhouse gas emissions per capita in high-income countries.\n",
    "# Solution:\n",
    "# 1. load_data(dataset='Greenhouse gases emission per capita, carbon dioxide-equivalents, tons', output_dataframe_name='ghg_emissions') \n",
    "# 2. load_geodata(geodataset='Countries', output_geodataframe_name='countries_geodata') \n",
    "# 3. get_unique_values(dataframe_name='countries_geodata', column='INCOME_GRP') \n",
    "# 4. filter_categorical(dataframe_name='countries_geodata', filters=\"'INCOME_GRP': ['1. High income: OECD', '2. High income: nonOECD']\", output_dataframe_name='high_income_countries') \n",
    "# 5. merge_dataframes(dataframe_name='ghg_emissions', geodataframe_name='high_income_countries', statkey='Country Name', geokey='NAME_EN', output_dataframe_name='merged_ghg_high_income') \n",
    "# 6. make_map(dataframe_name='merged_ghg_high_income', mappingkey='2023', legendtext='Greenhouse Gas Emissions per Capita (tons) - 2023', colormap='Environment')\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examples of tasks for the group 'Spatial Operations'\n",
    "\n",
    "# feasible_tasks_examples = f\"\"\"\n",
    "# 1.How many people were affected by flood of August 2018 in Bangladesh?\n",
    "# Solution:\n",
    "# 1. get_raster_path(rasterdataset='Tibetan Plato South Asia flood extent August 2018') \n",
    "# 2. get_raster_path(rasterdataset='Bangladesh population 2018, people, resolution 3 arc or apprx 100 m') \n",
    "# 3. analyze_raster_overlap(raster1_path='zip://G:/My Drive/Geo Agent/Tasks data/GeoData/DFO_4665_From_20180802_to_20180810.zip!/DFO_4665_From_20180802_to_20180810.tif', raster2_path='G:/My Drive/Geo Agent/Tasks data/GeoData/bgd_ppp_2018_UNadj.tif', output_variable_name='flood_impact_analysis') \n",
    "\n",
    "# 2.How many people live within 1 km from a railway in Bangladesh?\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='Railway lines in Bangladesh', output_geodataframe_name='bangladesh_railways') \n",
    "# 2. create_buffer(geodataframe_name='bangladesh_railways', buffer_size='1000', output_geodataframe_name='railway_buffer') \n",
    "# 3. get_raster_path(rasterdataset='Bangladesh population 2018, people, resolution 3 arc or apprx 100 m') \n",
    "# 4. get_values_from_raster_with_geometries(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/bgd_ppp_2018_UNadj.tif', geodataframe_name='railway_buffer', output_variable_name='population_in_buffer') \n",
    "\n",
    "# 3.How many towns in USA within 5 km from an Amtrak station have accumulated snow cover in the current season over 3 feet?\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='Amtrak railway stations', output_geodataframe_name='amtrak_stations') \n",
    "# 2. load_geodata(geodataset='Cities and Towns of the United States, 2014', output_geodataframe_name='us_towns') \n",
    "# 3. create_buffer(geodataframe_name='amtrak_stations', buffer_size='5000', output_geodataframe_name='amtrak_buffer') \n",
    "# 4. select_features_by_spatial_relationship(features_geodataframe_name='us_towns', reference_geodataframe_name='amtrak_buffer', spatial_predicate='within', output_geodataframe_name='towns_near_amtrak') \n",
    "# 5. get_raster_path(rasterdataset='Accumulated snow cover season 2024-2025 till February 3, 2025, USA, inches') \n",
    "# 6. filter_points_by_raster_values(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/sfav2_CONUS_2024093012_to_2025020312.tif', points_geodataframe_name='towns_near_amtrak', value_column='snow_depth', filter_type='greater', threshold1='36', output_geodataframe_name='snowy_towns_near_amtrak')\n",
    "\n",
    "# 4.Make a map of towns in USA that are within 1 mile from an Amtrak station and accumulated 3-4 feet of snow in the last season.\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='Amtrak railway stations', output_geodataframe_name='amtrak_stations') \n",
    "# 2. load_geodata(geodataset='Cities and Towns of the United States, 2014', output_geodataframe_name='us_towns') \n",
    "# 3. get_raster_path(rasterdataset='Accumulated snow cover seazon 2023-2024, USA, inches') \n",
    "# 4. create_buffer(geodataframe_name='amtrak_stations', buffer_size='1609', output_geodataframe_name='amtrak_buffers') \n",
    "# 5. select_features_by_spatial_relationship(features_geodataframe_name='us_towns', reference_geodataframe_name='amtrak_buffers', spatial_predicate='within', output_geodataframe_name='towns_near_amtrak') \n",
    "# 6. filter_points_by_raster_values(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/sfav2_CONUS_2023093012_to_2024093012.tif', points_geodataframe_name='towns_near_amtrak', value_column='snow_depth', output_geodataframe_name='final_towns', filter_type='between', threshold1='36', threshold2='48') \n",
    "# 7. make_map(dataframe_name='final_towns', mappingkey='snow_depth', legendtext='Snow Depth (inches)', colormap='Hazards')\n",
    "\n",
    "# 5. How many people in USA live in 5-mile radius from an Amtrak station?\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='Amtrak railway stations', output_geodataframe_name='amtrak_stations') \n",
    "# 2. get_raster_path(rasterdataset='USA population 2020, people, resolution 1 km') \n",
    "# 3. create_buffer(geodataframe_name='amtrak_stations', buffer_size='8047', output_geodataframe_name='amtrak_stations_buffer') \n",
    "# 4. get_values_from_raster_with_geometries(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/usa_ppp_2020_1km_Aggregated_UNadj.tif', geodataframe_name='amtrak_stations_buffer', output_variable_name='population_within_5_miles', plot_result='True') \n",
    "\n",
    "# 6. List and make a map of all counties that touch or include the Mississippi River (Penn State)\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='Rivers in North America', output_geodataframe_name='mississippi_river') \n",
    "# 2. load_geodata(geodataset='USA countires borders', output_geodataframe_name='usa_counties') \n",
    "# 3. filter_categorical(dataframe_name='mississippi_river', filters=\"{\"'NameEn': 'Mississippi River'\"}\", output_dataframe_name='mississippi_river_filtered') \n",
    "# 4. select_features_by_spatial_relationship(features_geodataframe_name='usa_counties', reference_geodataframe_name='mississippi_river_filtered', spatial_predicate='intersects', output_geodataframe_name='counties_touching_mississippi') \n",
    "# 5. visualize_geographies(geodataframe_name='counties_touching_mississippi', basemap_style='OpenStreetMap', geometry_color='blue', geometry_alpha='0.6', geometry_linewidth='1.0', title='Counties Touching or Including the Mississippi River') \n",
    "\n",
    "# 7. Generate a list of all states whose boundaries touch Wyoming (Penn State)\n",
    "# Solution:\n",
    "# 1. load_geodata(geodataset='USA states borders', output_geodataframe_name='us_states') \n",
    "# 2. filter_categorical(dataframe_name='us_states', filters=\"{\"'NAME': 'Wyoming'\"}\", output_dataframe_name='wyoming_state') \n",
    "# 3. select_features_by_spatial_relationship(features_geodataframe_name='us_states', reference_geodataframe_name='wyoming_state', spatial_predicates='['touches']', output_geodataframe_name='wyoming_neighbors') \n",
    "# 4. get_unique_values(dataframe_name='wyoming_neighbors', column='NAME') \n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of tasks for group 'Heatmaps, Contour lines'\n",
    "\n",
    "feasible_tasks_examples = f\"\"\"\n",
    "1. Make a heatmap final size of fire incidents in USA\n",
    "Solution\n",
    "1. load_geodata(geodataset='Current Wildland Fire Incident Locations, size in acres', output_geodataframe_name='fires') \n",
    "2. make_heatmap(geodataframe_name='fires', value_column='IncidentSi', map_style='carto-positron', radius='30') \n",
    " \n",
    "2. Make a heatmap of TB cases in Massachusetts\n",
    "Solution\n",
    "1. load_data(dataset='Incidence of Tuberculosis Disease 2023 Massachusetts Counties', output_dataframe_name='tb_cases') \n",
    "2. load_geodata(geodataset='USA counties borders', output_geodataframe_name='ma_counties') \n",
    "3. filter_categorical(dataframe_name='ma_counties', filters=\"\", output_dataframe_name='massachusetts_counties') \n",
    "4. merge_dataframes(dataframe_name='tb_cases', geodataframe_name='massachusetts_counties', statkey='County', geokey='NAME', output_dataframe_name='merged_tb_data') \n",
    "5. get_centroids(geodataframe_name='merged_tb_data', output_geodataframe_name='centroids_tb_data') \n",
    "6. make_heatmap(geodataframe_name='centroids_tb_data', value_column='Number of Cases', output_html_name='tb_cases_heatmap.html', map_style='carto-positron', radius='15') \n",
    " \n",
    "3.Chart contour lines for accumulated snow fall in winter 2023-2024\n",
    "Solution:\n",
    "1. get_raster_path(rasterdataset='Accumulated snow cover season 2023-2024, USA, inches') \n",
    "2. get_raster_description(raster_path='') \n",
    "3. plot_contour_lines(raster_path='', output_geodataframe_name='snow_contours_2023_2024', interval='5', min_value='0', plot_result='True', title='Contour Lines for Accumulated Snowfall in Winter 2023-2024') \n",
    " \n",
    "4.Show zones with similar population in Bangladesh\n",
    "Solution:\n",
    "1. get_raster_path(rasterdataset='Bangladesh population 2018, people, resolution 3 arc or apprx 100 m') \n",
    "2. get_raster_description(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/bgd_ppp_2018_UNadj.tif') \n",
    "3. plot_contour_lines(raster_path='G:/My Drive/Geo Agent/Tasks data/GeoData/bgd_ppp_2018_UNadj.tif', output_geodataframe_name='bangladesh_pop_contours', interval='500', title='Population Density Zones in Bangladesh (2018)') \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusing_tasks_manual = f\"\"\"\n",
    "1) Map population density in Sub-Saharan Africa.\n",
    "Why not solvable:\n",
    "No data on countries areas in sq km.\n",
    "\n",
    "2) Map value of agriculture sector in USA counties along the Great Lakes shores.\n",
    "Why not solvable:\n",
    "No data on value of agriculture sector/production by USA counties is provided\n",
    "No data allowing calculate the value is provided\n",
    "\n",
    "3) Map forest areas per capita in 50 km zone from the Mekong river.\n",
    "Why not solvable:\n",
    "No Mekong river geometry is provided, no forest areas geometry or raster is provided.\n",
    "\n",
    "4) Map GHG emissions in major urban areas\n",
    "Why not solvable:\n",
    "No data on GHG by cities or urban areas\n",
    "No poligon/point geodataset with urban areas \n",
    "No point geodataset with cities locations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task set 4\n",
    "# PROMPT_FEASIBLE_TASK = f\"\"\"\n",
    "# Here are examples of the tasks that the LLM can solve with these tools and datasets:\n",
    "# <EXAMPLES>{feasible_tasks_examples}</EXAMPLES>\n",
    "# Generate {GENERATE_FEASIBLE} more questions that are possible to solve using these tools and data. \n",
    "# <GUIDELINES>\n",
    "#  - Make sure that datasets from DATA_CATALOG in DATA are enough to solve the tasks.\n",
    "#  - Make sure usage of raster files or spatial selection tool is required.\n",
    "#  - Make sure that tools from TOOLS are enough.\n",
    "#  - Make sure classifications of the countires are enough to solve the task.\n",
    "#  - Do not generate solution. Only the task.\n",
    "#  - Please, present the results as a python list with no additional text.\n",
    "#  - For this set of tasks, make sure that most require to make a heatmap or a contour lines map.\n",
    "# </GUIDELINES>\n",
    "# Follow GUIDELINES while providing response. \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the examples of the tasks, you can tailor the prompt to generate tasks for different groups of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task set 3\n",
    "PROMPT_FEASIBLE_TASK = f\"\"\"\n",
    "Generate {GENERATE_FEASIBLE} more questions that are possible to solve using these tools and data. \n",
    "<GUIDELINES>\n",
    " - Make sure that datasets from DATA_CATALOG in DATA are enough to solve the tasks.\n",
    " - Make sure usage of raster files or spatial selection tool is required.\n",
    " - Make sure that tools from TOOLS are enough.\n",
    " - Make sure classifications of the countires are enough to solve the task.\n",
    " - Do not generate solution. Only the task.\n",
    " - Please, present the results as a python list with no additional text.\n",
    "</GUIDELINES>\n",
    "Follow GUIDELINES while providing response. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task set 2\n",
    "# PROMPT_FEASIBLE_TASK = f\"\"\"\n",
    "# Here are examples of the tasks that the LLM can solve with these tools and datasets:\n",
    "# <EXAMPLES>{feasible_tasks_examples}</EXAMPLES>\n",
    "# Generate {GENERATE_FEASIBLE} more questions that are possible to solve using these tools and data. \n",
    "# <GUIDELINES>\n",
    "#  - Make sure that datasets from DATA_CATALOG in DATA are enough to solve the tasks.\n",
    "#  - Make sure that tools from TOOLS are enough.\n",
    "#  - Make sure classifications of the countires are enough to solve the task.\n",
    "#  - Do not generate solution. Only the task.\n",
    "#  - Please, present the results as a python list with no additional text.\n",
    "# </GUIDELINES>\n",
    "# Follow GUIDELINES while providing response. \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_CONFUSING_TASK = f\"\"\"\n",
    "Here are examples of the tasks that the LLM can NOT solve with these tools and datasets, but they look similar to the ones it can solve:\n",
    "{confusing_tasks_manual}\n",
    "Generate {GENERATE_CONFUSING} more questions that look similar, but cannot be answered using these tools and datasets.\n",
    " Please, present the results as a python list with no additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"Create a bivariate map showing the relationship between forest area (% of land area) and CO2 emissions per capita in South American countries for the year 2020. Use appropriate color schemes for environmental and hazard variables.\",\n",
      "    \n",
      "    \"Compare total freshwater withdrawals (billion cubic meters) between East Asian and South Asian countries in 2015, visualizing the results as a choropleth map. Calculate the mean withdrawal values for both regions.\",\n",
      "    \n",
      "    \"Create a map showing GDP per capita (current US$) for African countries in 2019, but only for countries that have power stations within their borders. Use the spatial relationship selection tool to identify qualifying countries.\",\n",
      "    \n",
      "    \"Generate a visualization comparing forest area (sq. km) between high-income OECD countries and upper-middle-income countries in 2018. Calculate the mean forest area for each income group.\",\n",
      "    \n",
      "    \"Create a map showing the electric power consumption (kWh per capita) in 2019 for countries in Western Europe, but only include countries that have at least one mineral extraction facility within 100km of their borders. Use appropriate buffer and spatial selection tools.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Generating the feasible tasks. \n",
    "\n",
    "llm = ChatAnthropic(model=MODEL_CLAUDE, temperature=TEMPERATURE, max_tokens = 4000)\n",
    "input = SETTING_PROMPT+PROMPT_FEASIBLE_TASK\n",
    "response = llm.invoke(input)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_tasks = [\n",
    "    # insert here tasks generated by Claude. Sonnet generates a string, not a list, but since it is formatted as a list, simple copy-paste and assigning it to a valiable works.\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the tasks. Note that metadata will be later filled with information on model that generated canditate solutions, model that evaluated them, etc. It is OK to leave it empty for now.\n",
    "\n",
    "file_name = \"draftTaskSet.json\"\n",
    "tasks = TaskSet(metadata = {}, tasks = [Task(task_text = draft_task) for draft_task in draft_tasks])\n",
    "tasks.save_to_file(file_name, DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generrating confusing tasks - check the 'feasible' task first, most likely there are enough tasks that are not actiually solvable there. \n",
    "# Use the code from above cell to save the tasks\n",
    "\n",
    "llm = ChatAnthropic(model=MODEL_CLAUDE, temperature=TEMPERATURE, max_tokens = 4000)\n",
    "input = SETTING_PROMPT+PROMPT_CONFUSING_TASK\n",
    "response = llm.invoke(input)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
